{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did the rainy cook really turn the travel? #Â§ßËøû...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4249570ü•≥ü•≥inside travel simply \\n#È¢úËâ≤Èô™Áé© #Â•≥Âñò #ÊñáÊè¥ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astounding -- 98% from one religion in FBI's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I‚Äôm sorry, I‚Äôm a little bit high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's fascinating - I guess not too surprising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"The core measure the RBA looks at is the ‚Äòexc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A1: On the First Weekend of Summer We Took the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cheap Flights: Dallas to Madrid $586-$599 r/t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@NISAmerica @garrrzzz *Googles how to harness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Let a 30 year old be a magical girl, let the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  Did the rainy cook really turn the travel? #Â§ßËøû...\n",
       "1  4249570ü•≥ü•≥inside travel simply \\n#È¢úËâ≤Èô™Áé© #Â•≥Âñò #ÊñáÊè¥ ...\n",
       "2  Astounding -- 98% from one religion in FBI's t...\n",
       "3                   I‚Äôm sorry, I‚Äôm a little bit high\n",
       "4  It's fascinating - I guess not too surprising ...\n",
       "5  \"The core measure the RBA looks at is the ‚Äòexc...\n",
       "6  A1: On the First Weekend of Summer We Took the...\n",
       "7  Cheap Flights: Dallas to Madrid $586-$599 r/t ...\n",
       "8  @NISAmerica @garrrzzz *Googles how to harness ...\n",
       "9  Let a 30 year old be a magical girl, let the m..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lectura del csv\n",
    "DATA_FILE = 'Travel Tweets.csv'\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text normalization / remove special characters / emojis \n",
    "def remove_emoji(string):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', string) \n",
    "\n",
    "\n",
    "def clean_tweet(text):\n",
    "    if type(text) == float:\n",
    "        return \"\"\n",
    "    temp = text.lower() #to lowercase\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)#@user\n",
    "    temp = re.sub(r'@\\w+', '', temp) #delete usernames mentions\n",
    "    temp = re.sub(\"#\",\"\", temp)#hashtag\n",
    "    temp = remove_emoji(temp)\n",
    "    temp = re.sub(r'[^\\w\\s\\d]', '', temp) #remove special characters\n",
    "    temp = re.sub(r'(.)\\1+', r'\\1\\1', temp)#duplicated\n",
    "    temp = re.sub(r'http\\S+', '', temp)#url\n",
    "    temp = re.sub('[()!?]', ' ', temp)#parenthesis\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)#square brackets\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)#only alphanumeric\n",
    "    temp = temp.strip() #extra white spaces\n",
    "    return temp\n",
    "\n",
    "data['Tweet'] = data['Tweet'].map(lambda x : clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did the rainy cook really turn the travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4249570inside travel simply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astounding  98 from one religion in fbis trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im sorry im a little bit high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its fascinating  i guess not too surprising fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the core measure the rba looks at is the excl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1 on the first weekend of summer we took the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheap flights dallas to madrid 586599 rt augno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>googles how to harness orbal energy to time tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>let a 30 year old be a magical girl let the mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0          did the rainy cook really turn the travel\n",
       "1                        4249570inside travel simply\n",
       "2  astounding  98 from one religion in fbis trave...\n",
       "3                      im sorry im a little bit high\n",
       "4  its fascinating  i guess not too surprising fo...\n",
       "5  the core measure the rba looks at is the excl ...\n",
       "6  a1 on the first weekend of summer we took the ...\n",
       "7  cheap flights dallas to madrid 586599 rt augno...\n",
       "8  googles how to harness orbal energy to time tr...\n",
       "9  let a 30 year old be a magical girl let the mi..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     corrected_tweet \u001b[39m=\u001b[39m [spell\u001b[39m.\u001b[39mcorrection(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mTweet\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m corrected_tweet\n\u001b[1;32m---> 12\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mTweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mTweet\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(corrected_tweet)\n\u001b[0;32m     14\u001b[0m data\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[52], line 9\u001b[0m, in \u001b[0;36mcorrected_tweet\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrected_tweet\u001b[39m(tweet):\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Correcci√≥n ortogr√°fica del tweet\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     corrected_tweet \u001b[39m=\u001b[39m [spell\u001b[39m.\u001b[39;49mcorrection(token) \u001b[39mfor\u001b[39;49;00m token \u001b[39min\u001b[39;49;00m data[\u001b[39m'\u001b[39;49m\u001b[39mTweet\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m corrected_tweet\n",
      "Cell \u001b[1;32mIn[52], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrected_tweet\u001b[39m(tweet):\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Correcci√≥n ortogr√°fica del tweet\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     corrected_tweet \u001b[39m=\u001b[39m [spell\u001b[39m.\u001b[39;49mcorrection(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mTweet\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m corrected_tweet\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:158\u001b[0m, in \u001b[0;36mSpellChecker.correction\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The most probable correct spelling for the word\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    word (str): The word to correct\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m    str: The most likely candidate or None if no correction is present\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m word \u001b[39m=\u001b[39m ensure_unicode(word)\n\u001b[1;32m--> 158\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcandidates(word)\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m candidates:\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:185\u001b[0m, in \u001b[0;36mSpellChecker.candidates\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distance \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 185\u001b[0m     tmp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mknown(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__edit_distance_alt(res)))\n\u001b[0;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m tmp:\n\u001b[0;32m    187\u001b[0m         \u001b[39mreturn\u001b[39;00m tmp\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36mSpellChecker.__edit_distance_alt\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[39m=\u001b[39m [ensure_unicode(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[39m=\u001b[39m [w \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_case_sensitive \u001b[39melse\u001b[39;00m w\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tmp_words \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m [e2 \u001b[39mfor\u001b[39;49;00m e1 \u001b[39min\u001b[39;49;00m tmp \u001b[39mfor\u001b[39;49;00m e2 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknown(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medit_distance_1(e1))]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[39m=\u001b[39m [ensure_unicode(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[39m=\u001b[39m [w \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_case_sensitive \u001b[39melse\u001b[39;00m w\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tmp_words \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m [e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m tmp \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknown(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medit_distance_1(e1))]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:198\u001b[0m, in \u001b[0;36mSpellChecker.known\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The subset of `words` that appear in the dictionary of words\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m    words (list): List of words to determine which are in the corpus\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m    set: The set of those words from the input that are in the corpus\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m tmp_words \u001b[39m=\u001b[39m [ensure_unicode(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m words]\n\u001b[1;32m--> 198\u001b[0m tmp \u001b[39m=\u001b[39m [w \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_case_sensitive \u001b[39melse\u001b[39;49;00m w\u001b[39m.\u001b[39;49mlower() \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m tmp_words]\n\u001b[0;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m {w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tmp \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_frequency\u001b[39m.\u001b[39mdictionary \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_if_should_check(w)}\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\spellchecker\\spellchecker.py:198\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The subset of `words` that appear in the dictionary of words\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m    words (list): List of words to determine which are in the corpus\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m    set: The set of those words from the input that are in the corpus\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m tmp_words \u001b[39m=\u001b[39m [ensure_unicode(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m words]\n\u001b[1;32m--> 198\u001b[0m tmp \u001b[39m=\u001b[39m [w \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_case_sensitive \u001b[39melse\u001b[39;00m w\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tmp_words]\n\u001b[0;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m {w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tmp \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_frequency\u001b[39m.\u001b[39mdictionary \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_if_should_check(w)}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Spell-Checking  ---pip install pyspellchecker--- most heavy cell bc the ammount of tweets\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Crear una instancia del corrector ortogr√°fico\n",
    "spell = SpellChecker()\n",
    "\n",
    "def corrected_tweet(tweet):\n",
    "    # Correcci√≥n ortogr√°fica del tweet\n",
    "    corrected_tweet = [spell.correction(token) for token in data['Tweet']]\n",
    "    return corrected_tweet\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(corrected_tweet)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did the rainy cook really turn the travel</td>\n",
       "      <td>[rainy, cook, really, turn, travel]</td>\n",
       "      <td>([rainy, cook, really, turn, travel], [raini, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4249570inside travel simply</td>\n",
       "      <td>[4249570, inside, travel, simply]</td>\n",
       "      <td>([4249570, inside, travel, simply], [4249570, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astounding  98 from one religion in fbis trave...</td>\n",
       "      <td>[astounding, 98, one, religion, fbis, travel, ...</td>\n",
       "      <td>([astounding, 98, one, religion, fbis, travel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im sorry im a little bit high</td>\n",
       "      <td>[im, sorry, im, little, bit, high]</td>\n",
       "      <td>([im, sorry, im, little, bit, high], [im, sorr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its fascinating  i guess not too surprising fo...</td>\n",
       "      <td>[fascinating, guess, surprising, international...</td>\n",
       "      <td>([fascinating, guess, surprising, internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the core measure the rba looks at is the excl ...</td>\n",
       "      <td>[core, measure, rba, looks, excl, fuel, fruit,...</td>\n",
       "      <td>([core, measure, rba, looks, excl, fuel, fruit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1 on the first weekend of summer we took the ...</td>\n",
       "      <td>[a1, first, weekend, summer, took, south, bass...</td>\n",
       "      <td>([a1, first, weekend, summer, took, south, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheap flights dallas to madrid 586599 rt augno...</td>\n",
       "      <td>[cheap, flights, dallas, madrid, 586599, rt, a...</td>\n",
       "      <td>([cheap, flights, dallas, madrid, 586599, rt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>googles how to harness orbal energy to time tr...</td>\n",
       "      <td>[googles, harness, orbal, energy, time, travel...</td>\n",
       "      <td>([googles, harness, orbal, energy, time, trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>let a 30 year old be a magical girl let the mi...</td>\n",
       "      <td>[let, 30, year, old, magical, girl, let, middl...</td>\n",
       "      <td>([let, 30, year, old, magical, girl, let, midd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0          did the rainy cook really turn the travel   \n",
       "1                        4249570inside travel simply   \n",
       "2  astounding  98 from one religion in fbis trave...   \n",
       "3                      im sorry im a little bit high   \n",
       "4  its fascinating  i guess not too surprising fo...   \n",
       "5  the core measure the rba looks at is the excl ...   \n",
       "6  a1 on the first weekend of summer we took the ...   \n",
       "7  cheap flights dallas to madrid 586599 rt augno...   \n",
       "8  googles how to harness orbal energy to time tr...   \n",
       "9  let a 30 year old be a magical girl let the mi...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [rainy, cook, really, turn, travel]   \n",
       "1                  [4249570, inside, travel, simply]   \n",
       "2  [astounding, 98, one, religion, fbis, travel, ...   \n",
       "3                 [im, sorry, im, little, bit, high]   \n",
       "4  [fascinating, guess, surprising, international...   \n",
       "5  [core, measure, rba, looks, excl, fuel, fruit,...   \n",
       "6  [a1, first, weekend, summer, took, south, bass...   \n",
       "7  [cheap, flights, dallas, madrid, 586599, rt, a...   \n",
       "8  [googles, harness, orbal, energy, time, travel...   \n",
       "9  [let, 30, year, old, magical, girl, let, middl...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  ([rainy, cook, really, turn, travel], [raini, ...  \n",
       "1  ([4249570, inside, travel, simply], [4249570, ...  \n",
       "2  ([astounding, 98, one, religion, fbis, travel,...  \n",
       "3  ([im, sorry, im, little, bit, high], [im, sorr...  \n",
       "4  ([fascinating, guess, surprising, internationa...  \n",
       "5  ([core, measure, rba, looks, excl, fuel, fruit...  \n",
       "6  ([a1, first, weekend, summer, took, south, bas...  \n",
       "7  ([cheap, flights, dallas, madrid, 586599, rt, ...  \n",
       "8  ([googles, harness, orbal, energy, time, trave...  \n",
       "9  ([let, 30, year, old, magical, girl, let, midd...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization and stemming\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #list of void words\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Descargar la lista de palabras vac√≠as en ingl√©s\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenizador espec√≠fico para tweets\n",
    "tokenizer = TweetTokenizer()\n",
    "# Stemmer para ingl√©s\n",
    "stemmer = PorterStemmer()\n",
    "# Obtener la lista de palabras vac√≠as en ingl√©s\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenizar y filtrar palabras vac√≠as en los tweets\n",
    "def token_tweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopwords_en]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "#Stemming \n",
    "def stemmer_token(filtered_tokens):\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    return filtered_tokens,stemmed_tokens\n",
    "\n",
    "# Aplicar el procesamiento a la columna 'Tweet' y guardar los tokens en 'tokens'\n",
    "data['tokens'] = data['Tweet'].apply(token_tweet)\n",
    "data['stemmed_tokens'] = data['tokens'].apply(stemmer_token)\n",
    "# Imprimir el DataFrame resultante\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did the rainy cook really turn the travel</td>\n",
       "      <td>[rainy, cook, really, turn, travel]</td>\n",
       "      <td>([rainy, cook, really, turn, travel], [raini, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4249570inside travel simply</td>\n",
       "      <td>[4249570, inside, travel, simply]</td>\n",
       "      <td>([4249570, inside, travel, simply], [4249570, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astounding  98 from one religion in fbis trave...</td>\n",
       "      <td>[astounding, 98, one, religion, fbis, travel, ...</td>\n",
       "      <td>([astounding, 98, one, religion, fbis, travel,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im sorry im a little bit high</td>\n",
       "      <td>[im, sorry, im, little, bit, high]</td>\n",
       "      <td>([im, sorry, im, little, bit, high], [im, sorr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its fascinating  i guess not too surprising fo...</td>\n",
       "      <td>[fascinating, guess, surprising, international...</td>\n",
       "      <td>([fascinating, guess, surprising, internationa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the core measure the rba looks at is the excl ...</td>\n",
       "      <td>[core, measure, rba, looks, excl, fuel, fruit,...</td>\n",
       "      <td>([core, measure, rba, looks, excl, fuel, fruit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1 on the first weekend of summer we took the ...</td>\n",
       "      <td>[a1, first, weekend, summer, took, south, bass...</td>\n",
       "      <td>([a1, first, weekend, summer, took, south, bas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheap flights dallas to madrid 586599 rt augno...</td>\n",
       "      <td>[cheap, flights, dallas, madrid, 586599, rt, a...</td>\n",
       "      <td>([cheap, flights, dallas, madrid, 586599, rt, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>googles how to harness orbal energy to time tr...</td>\n",
       "      <td>[googles, harness, orbal, energy, time, travel...</td>\n",
       "      <td>([googles, harness, orbal, energy, time, trave...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>let a 30 year old be a magical girl let the mi...</td>\n",
       "      <td>[let, 30, year, old, magical, girl, let, middl...</td>\n",
       "      <td>([let, 30, year, old, magical, girl, let, midd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0          did the rainy cook really turn the travel   \n",
       "1                        4249570inside travel simply   \n",
       "2  astounding  98 from one religion in fbis trave...   \n",
       "3                      im sorry im a little bit high   \n",
       "4  its fascinating  i guess not too surprising fo...   \n",
       "5  the core measure the rba looks at is the excl ...   \n",
       "6  a1 on the first weekend of summer we took the ...   \n",
       "7  cheap flights dallas to madrid 586599 rt augno...   \n",
       "8  googles how to harness orbal energy to time tr...   \n",
       "9  let a 30 year old be a magical girl let the mi...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                [rainy, cook, really, turn, travel]   \n",
       "1                  [4249570, inside, travel, simply]   \n",
       "2  [astounding, 98, one, religion, fbis, travel, ...   \n",
       "3                 [im, sorry, im, little, bit, high]   \n",
       "4  [fascinating, guess, surprising, international...   \n",
       "5  [core, measure, rba, looks, excl, fuel, fruit,...   \n",
       "6  [a1, first, weekend, summer, took, south, bass...   \n",
       "7  [cheap, flights, dallas, madrid, 586599, rt, a...   \n",
       "8  [googles, harness, orbal, energy, time, travel...   \n",
       "9  [let, 30, year, old, magical, girl, let, middl...   \n",
       "\n",
       "                                      stemmed_tokens  is_relevant  \n",
       "0  ([rainy, cook, really, turn, travel], [raini, ...         True  \n",
       "1  ([4249570, inside, travel, simply], [4249570, ...         True  \n",
       "2  ([astounding, 98, one, religion, fbis, travel,...         True  \n",
       "3  ([im, sorry, im, little, bit, high], [im, sorr...         True  \n",
       "4  ([fascinating, guess, surprising, internationa...         True  \n",
       "5  ([core, measure, rba, looks, excl, fuel, fruit...         True  \n",
       "6  ([a1, first, weekend, summer, took, south, bas...         True  \n",
       "7  ([cheap, flights, dallas, madrid, 586599, rt, ...         True  \n",
       "8  ([googles, harness, orbal, energy, time, trave...         True  \n",
       "9  ([let, 30, year, old, magical, girl, let, midd...         True  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_relevant'] = True\n",
    "\n",
    "# Lista de palabras clave\n",
    "keywords = ['offer', 'destination', 'guide', 'discount', 'package', 'sale']\n",
    "\n",
    "# Funci√≥n para verificar si un tweet es relevante basado en palabras clave\n",
    "def tweet_relevant(tweet):\n",
    "    for keyword in keywords:\n",
    "        if keyword in tweet:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Marca los tweets relevantes como True en la columna 'is_relevant'\n",
    "data['is_relevant'] = data['Tweet'].apply(tweet_relevant)\n",
    "\n",
    "# Filtra los tweets relevantes\n",
    "relevant_tweets = data[data['is_relevant']]\n",
    "\n",
    "\n",
    "# Imprime los tweets relevantes\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deleting irrelevant tweets\n",
    "data = data[data['is_relevant'] == True]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did the rainy cook really turn the travel</td>\n",
       "      <td>([rainy, cook, really, turn, travel], [raini, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4249570inside travel simply</td>\n",
       "      <td>([4249570, inside, travel, simply], [4249570, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astounding  98 from one religion in fbis trave...</td>\n",
       "      <td>([astounding, 98, one, religion, fbis, travel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im sorry im a little bit high</td>\n",
       "      <td>([im, sorry, im, little, bit, high], [im, sorr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its fascinating  i guess not too surprising fo...</td>\n",
       "      <td>([fascinating, guess, surprising, internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the core measure the rba looks at is the excl ...</td>\n",
       "      <td>([core, measure, rba, looks, excl, fuel, fruit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1 on the first weekend of summer we took the ...</td>\n",
       "      <td>([a1, first, weekend, summer, took, south, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheap flights dallas to madrid 586599 rt augno...</td>\n",
       "      <td>([cheap, flights, dallas, madrid, 586599, rt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>googles how to harness orbal energy to time tr...</td>\n",
       "      <td>([googles, harness, orbal, energy, time, trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>let a 30 year old be a magical girl let the mi...</td>\n",
       "      <td>([let, 30, year, old, magical, girl, let, midd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0          did the rainy cook really turn the travel   \n",
       "1                        4249570inside travel simply   \n",
       "2  astounding  98 from one religion in fbis trave...   \n",
       "3                      im sorry im a little bit high   \n",
       "4  its fascinating  i guess not too surprising fo...   \n",
       "5  the core measure the rba looks at is the excl ...   \n",
       "6  a1 on the first weekend of summer we took the ...   \n",
       "7  cheap flights dallas to madrid 586599 rt augno...   \n",
       "8  googles how to harness orbal energy to time tr...   \n",
       "9  let a 30 year old be a magical girl let the mi...   \n",
       "\n",
       "                                       output_tokens  \n",
       "0  ([rainy, cook, really, turn, travel], [raini, ...  \n",
       "1  ([4249570, inside, travel, simply], [4249570, ...  \n",
       "2  ([astounding, 98, one, religion, fbis, travel,...  \n",
       "3  ([im, sorry, im, little, bit, high], [im, sorr...  \n",
       "4  ([fascinating, guess, surprising, internationa...  \n",
       "5  ([core, measure, rba, looks, excl, fuel, fruit...  \n",
       "6  ([a1, first, weekend, summer, took, south, bas...  \n",
       "7  ([cheap, flights, dallas, madrid, 586599, rt, ...  \n",
       "8  ([googles, harness, orbal, energy, time, trave...  \n",
       "9  ([let, 30, year, old, magical, girl, let, midd...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear pares de entrada-salida\n",
    "# Seleccionar las columnas relevantes\n",
    "datainputs = data[[\"Tweet\", \"stemmed_tokens\"]]\n",
    "\n",
    "# Renombrar las columnas\n",
    "datainputs.columns = [\"input_text\", \"output_tokens\"]\n",
    "\n",
    "\n",
    "# Crear una lista de pares de entrada-salida\n",
    "pairs = datainputs.values.tolist()\n",
    "\n",
    "# Visualizar los primeros 5 pares\n",
    "datainputs.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del conjunto de entrenamiento: 138\n",
      "Tama√±o del conjunto de validaci√≥n: 30\n",
      "Tama√±o del conjunto de prueba: 30\n"
     ]
    }
   ],
   "source": [
    "#data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#train =70%\n",
    "#test = 15%\n",
    "# val = 15%\n",
    "\n",
    "# Divisi√≥n en conjunto de entrenamiento, validaci√≥n y prueba\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos\n",
    "print(\"Tama√±o del conjunto de entrenamiento:\", train_data.shape[0])\n",
    "print(\"Tama√±o del conjunto de validaci√≥n:\", val_data.shape[0])\n",
    "print(\"Tama√±o del conjunto de prueba:\", test_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
